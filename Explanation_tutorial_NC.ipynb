{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/DIG_GXAI/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from GNNModels.Models import *\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "dataset_name = \"Cora\"\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Planetoid', name=dataset_name, transform=NormalizeFeatures())\n",
    "data = dataset[0]  # Get the first graph object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is temporary model training, will be replaced with improting pretrained model, having problems with it currently\n",
    "\n",
    "# from torch_geometric.nn import GCNConv\n",
    "\n",
    "# class GCN(torch.nn.Module):\n",
    "#     def __init__(self, hidden_channels):\n",
    "#         super().__init__()\n",
    "#         torch.manual_seed(1)\n",
    "#         self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n",
    "#         self.conv2 = GCNConv(hidden_channels, dataset.num_classes)\n",
    "\n",
    "#     def forward(self, x, edge_index):\n",
    "#         x = self.conv1(x, edge_index)\n",
    "#         x = x.relu()\n",
    "#         #x = F.dropout(x, p=0.5, training=self.training)\n",
    "#         x = self.conv2(x, edge_index)\n",
    "#         return x\n",
    "\n",
    "# model = GCN(hidden_channels=16)\n",
    "\n",
    "# model = GCN(hidden_channels=32)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# def train():\n",
    "#       model.train()\n",
    "#       optimizer.zero_grad()  # Clear gradients.\n",
    "#       out = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "#       loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "#       val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "#       loss.backward()  # Derive gradients.\n",
    "#       optimizer.step()  # Update parameters based on gradients.\n",
    "#       return loss, val_loss\n",
    "\n",
    "# def test():\n",
    "#       model.eval()\n",
    "#       out = model(data.x, data.edge_index)\n",
    "#       pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "#       test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n",
    "#       test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n",
    "#       return test_acc, out\n",
    "\n",
    "\n",
    "# for epoch in range(200):\n",
    "#     loss, val_loss = train()\n",
    "#     if epoch%200 == 0:\n",
    "#           print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Validation loss: {val_loss:.4f}')\n",
    "\n",
    "# test_acc, out = test()\n",
    "# print(f'Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pretrained model from GNNModels\n",
    "\n",
    "model=get_model_pretrained('GCN','Cora',path='GNNModels/checkpoints/')\n",
    "criterion=torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd GrapthXAI-main\n",
    "# !pip insall -e .\n",
    "\n",
    "from graphxai.explainers import GNNExplainer, PGExplainer, IntegratedGradExplainer, PGMExplainer\n",
    "\n",
    "# the ones below we want to use from different libraries\n",
    "from graphxai.explainers import GNN_LRP, CAM\n",
    "\n",
    "# need to also use subgraph x from DIG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN Explainer and PGE Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "140it [00:00, 1252.20it/s]\n",
      "140it [00:00, 974.16it/s]\n",
      "140it [00:00, 721.94it/s]\n",
      "140it [00:00, 616.34it/s]\n",
      "140it [00:00, 827.37it/s]\n",
      "140it [00:00, 865.31it/s]\n",
      "140it [00:00, 664.02it/s]\n",
      "140it [00:00, 633.78it/s]\n",
      "140it [00:00, 834.34it/s]\n",
      "140it [00:00, 951.10it/s]\n",
      "140it [00:00, 968.33it/s]\n",
      "140it [00:00, 819.82it/s]\n",
      "140it [00:00, 886.23it/s]\n",
      "140it [00:00, 984.67it/s]\n",
      "140it [00:00, 949.69it/s]\n",
      "140it [00:00, 889.28it/s]\n",
      "140it [00:00, 904.95it/s]\n",
      "140it [00:00, 959.74it/s]\n",
      "140it [00:00, 959.50it/s]\n",
      "140it [00:00, 784.38it/s]\n",
      "140it [00:00, 635.76it/s]\n",
      "140it [00:00, 875.31it/s]\n",
      "140it [00:00, 984.07it/s] \n",
      "140it [00:00, 910.10it/s]\n",
      "129it [00:00, 920.77it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39m# PGE Explainer - discrete maks of node imp, discrete mask of edge imp\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[39m# needs name of emb layer of the model\u001b[39;00m\n\u001b[1;32m     22\u001b[0m pgex \u001b[39m=\u001b[39m PGExplainer(model, emb_layer_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mconv2\u001b[39m\u001b[39m'\u001b[39m,  max_epochs \u001b[39m=\u001b[39m \u001b[39m500\u001b[39m, lr \u001b[39m=\u001b[39m \u001b[39m0.01\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m pgex\u001b[39m.\u001b[39;49mtrain_explanation_model(data)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpge_imp_nodes\u001b[39m(node_idx):\n\u001b[1;32m     27\u001b[0m     node_exp \u001b[39m=\u001b[39m pgex\u001b[39m.\u001b[39mget_explanation_node(node_idx \u001b[39m=\u001b[39m node_idx, x \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mx, edge_index \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39medge_index)\n",
      "File \u001b[0;32m~/Desktop/UT-AUSTIN/SEM-1/Project-FML/GraphXAI/graphxai/explainers/pg_explainer.py:281\u001b[0m, in \u001b[0;36mPGExplainer.train_explanation_model\u001b[0;34m(self, dataset, forward_kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m tic \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[1;32m    280\u001b[0m \u001b[39mfor\u001b[39;00m iter_idx, node_idx \u001b[39min\u001b[39;00m tqdm\u001b[39m.\u001b[39mtqdm(\u001b[39menumerate\u001b[39m(x_dict\u001b[39m.\u001b[39mkeys())):\n\u001b[0;32m--> 281\u001b[0m     prob_with_mask, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__emb_to_edge_mask(\n\u001b[1;32m    282\u001b[0m         emb_dict[node_idx], \n\u001b[1;32m    283\u001b[0m         x \u001b[39m=\u001b[39;49m x_dict[node_idx], \n\u001b[1;32m    284\u001b[0m         edge_index \u001b[39m=\u001b[39;49m edge_index_dict[node_idx], \n\u001b[1;32m    285\u001b[0m         node_idx \u001b[39m=\u001b[39;49m node_idx,\n\u001b[1;32m    286\u001b[0m         forward_kwargs\u001b[39m=\u001b[39;49mforward_kwargs,\n\u001b[1;32m    287\u001b[0m         tmp\u001b[39m=\u001b[39;49mtmp, \n\u001b[1;32m    288\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    289\u001b[0m     loss_tmp \u001b[39m=\u001b[39m loss_fn(prob_with_mask[node_idx_dict[node_idx]], pred_dict[node_idx])\n\u001b[1;32m    290\u001b[0m     loss_tmp\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Desktop/UT-AUSTIN/SEM-1/Project-FML/GraphXAI/graphxai/explainers/pg_explainer.py:145\u001b[0m, in \u001b[0;36mPGExplainer.__emb_to_edge_mask\u001b[0;34m(self, emb, x, edge_index, node_idx, forward_kwargs, tmp, training)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_masks(x, edge_index, edge_mask)\n\u001b[1;32m    141\u001b[0m \u001b[39m# Compute the model prediction with edge mask\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39m#     tester = self.model(x, edge_index)\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39m#     print(tester)\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m prob_with_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(x, edge_index,\n\u001b[1;32m    146\u001b[0m                                forward_kwargs\u001b[39m=\u001b[39;49mforward_kwargs,\n\u001b[1;32m    147\u001b[0m                                return_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mprob\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    148\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clear_masks()\n\u001b[1;32m    150\u001b[0m \u001b[39mreturn\u001b[39;00m prob_with_mask, edge_mask\n",
      "File \u001b[0;32m~/Desktop/UT-AUSTIN/SEM-1/Project-FML/GraphXAI/graphxai/explainers/_base.py:116\u001b[0m, in \u001b[0;36m_BaseExplainer._predict\u001b[0;34m(self, x, edge_index, return_type, forward_kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39m# Compute unnormalized class score\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 116\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mto(device)(x, edge_index, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_kwargs)\n\u001b[1;32m    117\u001b[0m     \u001b[39mif\u001b[39;00m return_type \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    118\u001b[0m         out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/DIG_GXAI/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GitHub/FML-GNN_DisagreementProblem/GNNModels/Models.py:33\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     31\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mrelu()\n\u001b[1;32m     32\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(x, p\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[0;32m---> 33\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(x, edge_index)\n\u001b[1;32m     34\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/DIG_GXAI/lib/python3.10/site-packages/torch/nn/modules/module.py:1211\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1210\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m (\u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m-> 1211\u001b[0m         hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39;49m, \u001b[39minput\u001b[39;49m, result)\n\u001b[1;32m   1212\u001b[0m         \u001b[39mif\u001b[39;00m hook_result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1213\u001b[0m             result \u001b[39m=\u001b[39m hook_result\n",
      "File \u001b[0;32m~/Desktop/UT-AUSTIN/SEM-1/Project-FML/GraphXAI/graphxai/explainers/_base.py:192\u001b[0m, in \u001b[0;36m_BaseExplainer._get_activation.<locals>.get_activation.<locals>.hook\u001b[0;34m(model, inp, out)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhook\u001b[39m(model, inp, out):\n\u001b[0;32m--> 192\u001b[0m     activation[\u001b[39m'\u001b[39m\u001b[39mlayer\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39;49mdetach()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# GNN Explainer - discrete mask of node imp, soft mask of edge imp\n",
    "\n",
    "gnnexp = GNNExplainer(model)\n",
    "\n",
    "def gnn_imp_nodes(node_idx):\n",
    "\n",
    "    node_exp = gnnexp.get_explanation_node(node_idx = node_idx, x = data.x, edge_index = data.edge_index)\n",
    "\n",
    "    imp_nodes = []\n",
    "\n",
    "    for k in node_exp.node_reference.keys():\n",
    "\n",
    "        if node_exp.node_imp[node_exp.node_reference[k]].item() == 1:\n",
    "\n",
    "            imp_nodes.append(k)\n",
    "\n",
    "    return imp_nodes\n",
    "\n",
    "# PGE Explainer - discrete maks of node imp, discrete mask of edge imp\n",
    "\n",
    "# needs name of emb layer of the model\n",
    "pgex = PGExplainer(model, emb_layer_name = 'conv2',  max_epochs = 500, lr = 0.01)\n",
    "pgex.train_explanation_model(data)\n",
    "\n",
    "def pge_imp_nodes(node_idx):\n",
    "\n",
    "    node_exp = pgex.get_explanation_node(node_idx = node_idx, x = data.x, edge_index = data.edge_index)\n",
    "\n",
    "    imp_nodes = []\n",
    "\n",
    "    for k in node_exp.node_reference.keys():\n",
    "\n",
    "        if node_exp.node_imp[node_exp.node_reference[k]].item() == 1:\n",
    "\n",
    "            imp_nodes.append(k)\n",
    "\n",
    "    return imp_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated Gradients and PGM Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrated gradients - soft mask of edge imp\n",
    "\n",
    "igex = IntegratedGradExplainer(model, criterion=criterion)\n",
    "\n",
    "def ig_imp_nodes(node_idx):\n",
    "\n",
    "    node_exp = igex.get_explanation_node(node_idx = node_idx, x = data.x, edge_index = data.edge_index, y = data.y)\n",
    "\n",
    "    imp_nodes = []\n",
    "\n",
    "    mask = torch.sigmoid(node_exp.node_imp) >= 0.5\n",
    "\n",
    "    for k in node_exp.node_reference.keys():\n",
    "\n",
    "        if mask[node_exp.node_reference[k]].item() == 1:\n",
    "        \n",
    "            imp_nodes.append(k)\n",
    "\n",
    "    return imp_nodes\n",
    "\n",
    "# PGME Explainer - discrete mask of node imp, randomised, can get ranking as well by asking for top 1 then 2 and so on\n",
    "\n",
    "pgm = PGMExplainer(model, explain_graph=False)\n",
    "\n",
    "def pgm_imp_nodes(node_idx, top = None):\n",
    "\n",
    "    np.random.seed(1998)\n",
    "\n",
    "    if top == None:\n",
    "\n",
    "        node_exp = pgm.get_explanation_node(node_idx = node_idx, x = data.x, edge_index = data.edge_index)\n",
    "\n",
    "    else: \n",
    "\n",
    "        node_exp = pgm.get_explanation_node(node_idx = node_idx, x = data.x, edge_index = data.edge_index, top_k_nodes=top)\n",
    "\n",
    "    imp_nodes = []\n",
    "\n",
    "    for k in node_exp.node_reference.keys():\n",
    "\n",
    "        if node_exp.node_imp[node_exp.node_reference[k]].item() == 1:\n",
    "        \n",
    "            imp_nodes.append(k)\n",
    "\n",
    "    return imp_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAM - soft mask of node importanct\n",
    "\n",
    "camex = CAM(model)\n",
    "\n",
    "def cam_imp_nodes(node_idx):\n",
    "\n",
    "    node_exp = camex.get_explanation_node(node_idx = node_idx, x = data.x, edge_index = data.edge_index, y = data.y)\n",
    "\n",
    "    imp_nodes = []\n",
    "\n",
    "    mask = torch.sigmoid(node_exp.node_imp) >= 0.5\n",
    "\n",
    "    for k in node_exp.node_reference.keys():\n",
    "\n",
    "        if mask[node_exp.node_reference[k]].item() == 1:\n",
    "        \n",
    "            imp_nodes.append(k)\n",
    "\n",
    "    return imp_nodes\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('DIG_GXAI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a96d9a9b024afc8122ecb662ff5349e8dc2ebea5f61559fdd75ed5db623e2825"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
